{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.Mlflow_Project.utils.utility import FileOperations\n",
    "import yaml\n",
    "\n",
    "class BasePipeline:\n",
    "    def __init__(self, model_path, config_path):\n",
    "        self.model = None\n",
    "        self.config_path = config_path\n",
    "        self.load_model(model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        try:\n",
    "            self.model = joblib.load(model_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Model file not found at {model_path}\")\n",
    "            self.model = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            self.model = None\n",
    "\n",
    "    def predict(self, data):\n",
    "        if self.model is not None:\n",
    "            return self.model.predict(data)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class ScalingPipeline(BasePipeline):\n",
    "    def __init__(self, model_path, config_path):\n",
    "        super().__init__(model_path, config_path)\n",
    "        self.scaler = None\n",
    "        self.load_scaler()\n",
    "\n",
    "    def load_scaler(self):\n",
    "        try:\n",
    "            config = FileOperations.read_yaml(self.config_path)\n",
    "            scaler_path = Path(config[\"data_transformation\"][\"scaler_name\"])\n",
    "            self.scaler = joblib.load(scaler_path)\n",
    "        except (FileNotFoundError, KeyError):\n",
    "            print(f\"Scaler file not found or config error.\")\n",
    "            self.scaler = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading scaler: {e}\")\n",
    "            self.scaler = None\n",
    "\n",
    "    def scale(self, data):\n",
    "        if self.scaler is not None:\n",
    "            return self.scaler.transform(data)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class PredictionPipeline(BasePipeline):\n",
    "    def __init__(self, model_path, config_path):\n",
    "        super().__init__(model_path, config_path)\n",
    "\n",
    "def main():\n",
    "    config_path = \"path/to/your/config.yaml\"  # Replace with the actual path to your YAML file\n",
    "    model_path = \"path/to/your/model.joblib\"  # Replace with the actual path to your model\n",
    "\n",
    "    scaling_pipeline = ScalingPipeline(model_path, config_path)\n",
    "    prediction_pipeline = PredictionPipeline(model_path, config_path)\n",
    "\n",
    "    # Load your data here\n",
    "    # data = ...\n",
    "\n",
    "    scaled_data = scaling_pipeline.scale(data)\n",
    "    predictions = prediction_pipeline.predict(scaled_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.Mlflow_Project.pipeline.prediction import ScalingPipeline, PredictionPipeline\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ... Your existing routes and code ...\n",
    "\n",
    "@app.route('/predict', methods=['POST', 'GET'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            # Reading the inputs given by the user\n",
    "            engine = int(request.form['engine'])\n",
    "            cycle = int(request.form['cycle'])\n",
    "            setting_1 = float(request.form['setting_1'])\n",
    "            # ... continue reading other input fields ...\n",
    "\n",
    "            # Convert all input data to a list, then a numpy array\n",
    "            data = [engine, cycle, setting_1, setting_2, LPC_outlet_temperature_degR, LPT_outlet_temperature_degR, bypass_duct_pressure_psia, HPC_outlet_pressure_psia, Physical_core_speed_rpm, HPC_outlet_Static_pressure_psia, Ratio_of_fuel_flow_to_Ps30_pps_psia, Bypass_Ratio, Bleed_Enthalpy, High_pressure_turbines_Cool_air_flow, Low_pressure_turbines_Cool_air_flow]\n",
    "            data = np.array(data).reshape(1, -1)\n",
    "\n",
    "            # Create an instance of ScalingPipeline\n",
    "            scl = ScalingPipeline(model_path=\"path/to/your/model.joblib\", config_path=\"path/to/your/config.yaml\")\n",
    "\n",
    "            # Scale the data\n",
    "            data_scaled = scl.scale(data)\n",
    "\n",
    "            # Create an instance of PredictionPipeline\n",
    "            obj = PredictionPipeline(model_path=\"path/to/your/model.joblib\", config_path=\"path/to/your/config.yaml\")\n",
    "\n",
    "            # Predict using the scaled data\n",
    "            predict = obj.predict(data_scaled)\n",
    "\n",
    "            return render_template('results.html', prediction=str(predict))\n",
    "        except Exception as e:\n",
    "            print(\"The Exception message is: \", e)\n",
    "            return \"Something is wrong\"\n",
    "    else:\n",
    "        return render_template('index.html')\n",
    "\n",
    "# ... The rest of your existing code ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=6060, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.Mlflow_Project.utils.utility import FileOperations\n",
    "import yaml\n",
    "\n",
    "class BasePipeline:\n",
    "    def __init__(self, model_path, config_path):\n",
    "        self.model = None\n",
    "        self.config_path = config_path\n",
    "        self.load_model(model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        try:\n",
    "            self.model = joblib.load(model_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Model file not found at {model_path}\")\n",
    "            self.model = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            self.model = None\n",
    "\n",
    "    def predict(self, data):\n",
    "        if self.model is not None:\n",
    "            return self.model.predict(data)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class ScalingPipeline(BasePipeline):\n",
    "    def __init__(self, model_path, config_path):\n",
    "        super().__init__(model_path, config_path)\n",
    "        self.scaler = None\n",
    "        self.load_scaler()\n",
    "\n",
    "    def load_scaler(self):\n",
    "        try:\n",
    "            with open(self.config_path, 'r') as config_file:\n",
    "                config = yaml.safe_load(config_file)\n",
    "                scaler_path = Path(config[\"data_transformation\"][\"scaler_name\"])\n",
    "                self.scaler = joblib.load(scaler_path)\n",
    "        except (FileNotFoundError, KeyError):\n",
    "            print(f\"Scaler file not found or config error.\")\n",
    "            self.scaler = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading scaler: {e}\")\n",
    "            self.scaler = None\n",
    "\n",
    "    def scale(self, data):\n",
    "        if self.scaler is not None:\n",
    "            return self.scaler.transform(data)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class PredictionPipeline(BasePipeline):\n",
    "    def __init__(self, model_path, config_path):\n",
    "        super().__init__(model_path, config_path)\n",
    "\n",
    "def main():\n",
    "    config_path = \"path/to/your/config.yaml\"  # Replace with the actual path to your YAML file\n",
    "    model_path = \"path/to/your/model.joblib\"  # Replace with the actual path to your model\n",
    "\n",
    "    scaling_pipeline = ScalingPipeline(model_path, config_path)\n",
    "    prediction_pipeline = PredictionPipeline(model_path, config_path)\n",
    "\n",
    "    # Load your data here\n",
    "    # data = ...\n",
    "\n",
    "    scaled_data = scaling_pipeline.scale(data)\n",
    "    predictions = prediction_pipeline.predict(scaled_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
